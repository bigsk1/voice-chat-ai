To use full cuda for xtts and faster whisper 

docker build -t voice-chat-ai:latest .


wsl docker run -d --gpus all -e "PULSE_SERVER=/mnt/wslg/PulseServer" -v /mnt/wslg/:/mnt/wslg/ --env-file .env --name voice-chat-ai -p 8000:8000 voice-chat-ai:latest


---


To use for no xtts and cpu on faster whisper ( only about 6gb image size )

docker build -t voice-chat-ai-no-xtts -f no-xtts-Dockerfile .

	
docker run -d
   -e "PULSE_SERVER=/mnt/wslg/PulseServer"
   -v \\wsl$\Ubuntu\mnt\wslg:/mnt/wslg/
   --env-file .env
   --name voice-chat-ai-no-xtts
   -p 8000:8000
   voice-chat-ai-no-xtts:latest